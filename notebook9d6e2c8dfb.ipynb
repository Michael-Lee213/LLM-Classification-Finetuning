{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12136746,"sourceType":"datasetVersion","datasetId":7643186}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 로드\ntrain = pd.read_csv('/kaggle/input/open12312312121212/train.csv')\ntest  = pd.read_csv('/kaggle/input/open12312312121212/test.csv')\n\n# 컬럼 정보\nprint(\"Train columns & dtypes:\")\nprint(train.dtypes)\nprint(\"\\nTrain 요약 통계:\")\nprint(train.describe(include='all'))\n\n# 샘플 데이터 확인\ndisplay(train.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T03:29:21.091995Z","iopub.execute_input":"2025-06-12T03:29:21.092282Z","iopub.status.idle":"2025-06-12T03:29:28.483707Z","shell.execute_reply.started":"2025-06-12T03:29:21.092250Z","shell.execute_reply":"2025-06-12T03:29:28.482712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model_a / model_b 등장 빈도\nprint(\"=== model_a 빈도 ===\")\nprint(train['model_a'].value_counts())\nprint(\"\\n=== model_b 빈도 ===\")\nprint(train['model_b'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T03:34:12.461712Z","iopub.execute_input":"2025-06-12T03:34:12.462033Z","iopub.status.idle":"2025-06-12T03:34:12.478367Z","shell.execute_reply.started":"2025-06-12T03:34:12.462009Z","shell.execute_reply":"2025-06-12T03:34:12.477353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# winner 컬럼을 하나의 label로 통합\ndef map_label(row):\n    if row['winner_model_a'] == 1: return 0\n    if row['winner_model_b'] == 1: return 1\n    if row['winner_tie']    == 1: return 2\n    return None\n\ntrain['label'] = train.apply(map_label, axis=1)\n\n# 라벨 분포 확인\nprint(train['label'].value_counts(normalize=True))\n# 0:A 선호  1:B 선호  2:tie\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T03:34:52.228649Z","iopub.execute_input":"2025-06-12T03:34:52.228974Z","iopub.status.idle":"2025-06-12T03:34:52.698686Z","shell.execute_reply.started":"2025-06-12T03:34:52.228947Z","shell.execute_reply":"2025-06-12T03:34:52.697550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) 간단한 카테고리 생성\ndef prompt_type(txt):\n    if txt.strip().endswith('?'): return 'question'\n    # 키워드는 필요시 추가\n    if any(kw in txt for kw in ['해줘','만들어','작성해','추천해']): \n        return 'command'\n    return 'other'\n\ntrain['prompt_type'] = train['prompt'].apply(prompt_type)\n\n# 2) 각 타입별 A,B 승률(0,1 비율) 계산\nres = (\n    train\n    .groupby('prompt_type')['label']\n    .value_counts(normalize=True)\n    .unstack(fill_value=0)\n    .rename(columns={0:'A_win_rate', 1:'B_win_rate', 2:'tie_rate'})\n)\ndisplay(res)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T03:35:34.827992Z","iopub.execute_input":"2025-06-12T03:35:34.828304Z","iopub.status.idle":"2025-06-12T03:35:34.924198Z","shell.execute_reply.started":"2025-06-12T03:35:34.828280Z","shell.execute_reply":"2025-06-12T03:35:34.923539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train 결측치 개수:\")\nprint(train.isnull().sum())\n\nprint(\"\\nTest 결측치 개수:\")\nprint(test.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T03:36:33.888684Z","iopub.execute_input":"2025-06-12T03:36:33.889421Z","iopub.status.idle":"2025-06-12T03:36:33.929968Z","shell.execute_reply.started":"2025-06-12T03:36:33.889394Z","shell.execute_reply":"2025-06-12T03:36:33.928967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nprint(\"Transformers version:\", transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T03:45:59.163087Z","iopub.execute_input":"2025-06-12T03:45:59.163435Z","iopub.status.idle":"2025-06-12T03:45:59.169341Z","shell.execute_reply.started":"2025-06-12T03:45:59.163407Z","shell.execute_reply":"2025-06-12T03:45:59.168271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) 라이브러리 불러오기\nimport time\nimport pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments\n)\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import softmax\n\n# 2) 데이터 로드 및 라벨 맵핑\ntrain_df = pd.read_csv('/kaggle/input/open12312312121212/train.csv')\ntest_df  = pd.read_csv('/kaggle/input/open12312312121212/test.csv')\n\ndef map_label(row):\n    if row['winner_model_a'] == 1: return 0\n    if row['winner_model_b'] == 1: return 1\n    if row['winner_tie']    == 1: return 2\n    return np.nan\n\ntrain_df['label'] = train_df.apply(map_label, axis=1)\ntrain_df = train_df.dropna(subset=['label']).astype({'label': 'int64'})\n\n# 3) 훈련/검증 분할\ntrain_pd, valid_pd = train_test_split(\n    train_df[['prompt','response_a','response_b','label']],\n    test_size=0.2,\n    stratify=train_df['label'],\n    random_state=42\n)\n\n# 4) HF Dataset 변환\nhf_train = Dataset.from_pandas(train_pd.reset_index(drop=True))\nhf_valid = Dataset.from_pandas(valid_pd.reset_index(drop=True))\n\n# 5) 토크나이저 & 모델 로드\nMODEL_NAME = 'distilbert-base-uncased'\ntokenizer  = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel      = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME, num_labels=3, ignore_mismatched_sizes=True\n)\n\n# 6) 전처리 함수\ndef preprocess(batch):\n    texts = [\n        f\"Prompt: {p}\\nA: {a}\\nB: {b}\"\n        for p, a, b in zip(batch['prompt'], batch['response_a'], batch['response_b'])\n    ]\n    return tokenizer(texts, truncation=True, max_length=256, padding='max_length')\n\ntokenized_train = hf_train.map(preprocess, batched=True)\ntokenized_valid = hf_valid.map(preprocess, batched=True)\n\n# 컬럼 정리\ntokenized_train = tokenized_train.rename_column('label', 'labels')\ntokenized_valid = tokenized_valid.rename_column('label', 'labels')\n\ntokenized_train.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\ntokenized_valid.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n\n# 7) 평가 지표 정의\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    probs = softmax(logits, axis=1)\n    return {\n        'log_loss': log_loss(labels, probs, labels=[0,1,2]),\n        'accuracy': accuracy_score(labels, np.argmax(logits, axis=-1))\n    }\n\n# 8) 최소 TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    learning_rate=3e-5,\n    num_train_epochs=3,\n    logging_steps=100\n)\n\n# 9) Trainer 초기화\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_valid,\n    compute_metrics=compute_metrics\n)\n\n# 10) 학습 실행\nstart = time.time()\ntrainer.train()\nprint(f\"Training finished in {(time.time()-start)/60:.2f} min\")\n\n# 11) 수동 검증\nmetrics = trainer.evaluate()\nprint(\"Evaluation results:\", metrics)\n\n# 12) 테스트 예측 & 제출\nhf_test = Dataset.from_pandas(test_df[['id','prompt','response_a','response_b']].reset_index(drop=True))\ntokenized_test = hf_test.map(preprocess, batched=True)\ntokenized_test.set_format(type='torch', columns=['input_ids','attention_mask'])\n\npreds = trainer.predict(tokenized_test)\nprobs = softmax(preds.predictions, axis=1)\n\nsubmission = pd.DataFrame({\n    'id':               test_df['id'],\n    'winner_model_a':   probs[:,0],\n    'winner_model_b':   probs[:,1],\n    'winner_tie':       probs[:,2],\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"submission.csv 생성 완료\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}